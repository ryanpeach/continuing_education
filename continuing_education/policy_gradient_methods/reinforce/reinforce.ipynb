{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2cd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "if __name__ == \"__main__\":\n",
    "    __this_file = Path().resolve() / \"reinforce.ipynb\"  # jupyter does not have __file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce\n",
    "\n",
    "The REINFORCE algorithm has us directly optimize a policy network $\\pi_\\theta(s)$ by maximizing the probability we will perform each action multiplied by the cumulative discounted future reward `of taking each action, following a training set of trajectories which it generates each iteration based on the current policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "First we will create the cartpole environment.\n",
    "\n",
    "The observation_space of cartpole is a 4-dimensional float vector,\n",
    "and the action_space is a discrete space with 2 possible actions (left or right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: (4,)\n",
      "Action size: 2\n",
      "Example state: (array([-0.0086627 , -0.04002628, -0.000721  , -0.0071444 ], dtype=float32), {})\n",
      "Action return: (array([-0.00946323,  0.15510601, -0.00086389, -0.30005473], dtype=float32), 1.0, False, False, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "def get_environment_space(env_name: str) -> tuple[tuple[int, ...], int]:\n",
    "    env = gym.make(env_name)\n",
    "    observation_space_shape = env.observation_space.shape\n",
    "    action_space_size = env.action_space.n\n",
    "    print(\"State size:\", observation_space_shape)\n",
    "    print(\"Action size:\", action_space_size)\n",
    "    state = env.reset()\n",
    "    print(f\"Example state: {state}\")\n",
    "    action_return = env.step(1)\n",
    "    print(f\"Action return: {action_return}\")\n",
    "    return observation_space_shape, action_space_size\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    OBSERVATION_SPACE_SHAPE, ACTION_SPACE_SIZE = get_environment_space(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "This is the policy network, in the paper represented by $\\pi_{\\theta}(s_t)$\n",
    "\n",
    "Meaning the policy $\\pi$ given the parameters $\\theta$ (which in this code\n",
    "represents the weights and biases of self.input, self.hidden and self.output) when\n",
    "doing a forward pass with the state $s$ at time $t$ as input.\n",
    "\n",
    "The network is very simple feed forward network, with relu activation functions and a softmax output.\n",
    "\n",
    "The output of the forward method is what the paper calls $\\pi_{\\theta}(a_i | s_t)$, which is a PDF due to the `softmax`.\n",
    "\n",
    "The action method is a translation from a numpy state vector into an int action, using the forward pass of the network and the REINFORCE score function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "# Lets make some types to make type annotation easier\n",
    "State = NewType(\"State\", npt.NDArray[np.float64])\n",
    "Action = NewType(\"Action\", int)\n",
    "Reward = NewType(\"Reward\", float)\n",
    "LogProb = NewType(\"LogProb\", Tensor)\n",
    "Loss = NewType(\"Loss\", Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    \"\"\"A classic policy network is one which takes in a state\n",
    "    and returns a probability distribution over the action space\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, *, state_size: int, action_size: int, hidden_sizes: List[int]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        This is a very simple feed forward network\n",
    "        with an input of size state_size, and output of size action_size\n",
    "        and ReLU activations between the layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert len(hidden_sizes) > 0, \"Need at least one hidden layer\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # Dimensions in the network are (batch_size, input_size, output_size)\n",
    "        network = []\n",
    "        network.append(nn.Linear(state_size, hidden_sizes[0]))  # Shape: (:, state_size, hidden_sizes[0])\n",
    "        network.append(nn.ReLU())\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            network.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))  # Shape: (:, hidden_sizes[i], hidden_sizes[i+1])\n",
    "            network.append(nn.ReLU())\n",
    "        network.append(nn.Linear(hidden_sizes[-1], action_size))  # Shape: (:, hidden_sizes[-1], action_size)\n",
    "        network.append(nn.Softmax(dim=-1))  # Softmax along the action dimension\n",
    "        self.network = nn.Sequential(*network).to(DEVICE)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Takes a state tensor and returns a probability distribution along the action space\"\"\"\n",
    "        state = state.to(DEVICE)\n",
    "        return self.network(state)\n",
    "    \n",
    "    def act(self, state: State) -> Tuple[Action, LogProb]:\n",
    "        \"\"\"Same as forward, instead of returning the entire distribution, we\n",
    "        return the maximum probability action\n",
    "        along with the log probability of that action\n",
    "        \"\"\"\n",
    "        # First we got to convert out of numpy and into pytorch\n",
    "        state_tensor = torch.from_numpy(state).float().unsqueeze(0)\n",
    "\n",
    "        # Now we can run the forward pass, whos output is a probability distribution\n",
    "        # along the action space\n",
    "        pdf = self.forward(state_tensor)\n",
    "        assert torch.isclose(pdf.sum().cpu(), torch.Tensor([1.0])).all(), \"The output of the network should be a probability distribution\"\n",
    "        assert pdf.cpu().shape[-1] == self.action_size, \"The output of the network should be a probability distribution over the action space\"\n",
    "\n",
    "        # Now we want to get the action that corresponds to the highest probability\n",
    "        # TODO: We could sample from the pdf instead of taking the greedy argmax\n",
    "        action_idx = torch.argmax(pdf)\n",
    "\n",
    "        # We also need the log probability of the action\n",
    "        # However, we are going to do backprop through the log probability of the action\n",
    "        # Therefore this needs to stay as a tensor\n",
    "        # The Category distribution in torch has a method for a backprop friendly log probability of one action from a multinomial distribution\n",
    "        log_prob = torch.distributions.Categorical(pdf).log_prob(action_idx)\n",
    "\n",
    "        # We return the action and the log probability of the action\n",
    "        return Action(action_idx.item()), log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (5): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Lets print this model architecture\n",
    "if __name__ == \"__main__\":\n",
    "    policy = Policy(state_size=4, action_size=2, hidden_sizes=[16, 16])\n",
    "    print(policy.network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - REINFORCE\n",
    "\n",
    "Training is done by assembling a sample of trajectories from the current policy, which are lists of tuples of (state, action, reward).\n",
    "\n",
    "First lets create some types to represent these trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# SAR stands for State, Action, Reward\n",
    "@dataclass\n",
    "class SAR:\n",
    "    state: State\n",
    "    action: Action\n",
    "    reward: Reward\n",
    "    log_prob: LogProb\n",
    "\n",
    "\n",
    "# A list of SAR representing a single episode\n",
    "Trajectory = NewType(\"Trajectory\", List[SAR])\n",
    "\n",
    "# A list of just the rewards from a single episode\n",
    "RewardTrajectory = NewType(\"RewardTrajectory\", List[Reward])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a nice helper function I found in the hugging face tutorial for normalization in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(returns: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Standard normalizes a tensor of float32s using the mean and standard deviation.\n",
    "    Handles floating point errors by adding a small epsilon to the denominator to avoid division by zero.\n",
    "\n",
    "    $\\frac{x - E[x]}_{std(x) + eps}$\n",
    "    \n",
    "    Ripped off from huggingface https://huggingface.co/learn/deep-rl-course/unit4/hands-on\n",
    "    \"\"\"\n",
    "    ## standardization of the returns is employed to make training more stable\n",
    "    eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "    ## eps is the smallest representable float, which is\n",
    "    # added to the standard deviation of the returns to avoid numerical instabilities\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a way to collect an episode from the environment given a policy. That is fairly simple using gymnasium.\n",
    "\n",
    "In the hugging face tutorial, this is represented by the step which says:\n",
    "\n",
    "Generate an episode $S_0, A_0, r_0, ..., S_{T-1}, A_{T-1}, r_{T-1}$ following $\\pi_{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "\n",
    "def collect_episode(*, env: Env, policy: Policy, max_t: int = 1000) -> Trajectory:\n",
    "    \"\"\"2.1 Returns the trajectory of one episode of using the policy.\n",
    "    \n",
    "    The output is a list of SAR tuples, where each tuple represents a state, action, reward tuple.\n",
    "\n",
    "    In the hugging face tutorial this is represented as:\n",
    "    \n",
    "    $S_0, A_0, r_0, ..., S_{T-1}, A_{T-1}, r_{T-1}$\n",
    "    \"\"\"\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    trajectory = []\n",
    "    for _ in range(max_t):\n",
    "        action, log_prob = policy.act(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        trajectory.append(\n",
    "            SAR(\n",
    "                state=State(state),\n",
    "                action=action,\n",
    "                reward=Reward(reward),\n",
    "                log_prob=LogProb(log_prob),\n",
    "            )\n",
    "        )\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return Trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function returns the rewards at each step of the episode, but for training purposes we need the discounted future rewards for each step. This is because we want to reward each action based on the future rewards it leads to, not just the immediate reward. We discount future rewards by a factor of $\\gamma$ for stability, and also because future rewards are less certain, and therefore less valuable.\n",
    "\n",
    "$G_t = \\sum_{k=t}^{T-1} \\gamma^{k-t} r_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0812a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_cumulative_discounted_future_rewards passed\n"
     ]
    }
   ],
   "source": [
    "# This is different than a reward trajectory\n",
    "# because each index is the discounted sum of future indexes\n",
    "# in the corresponding reward trajectory\n",
    "CumDiscFutureRewardTrajectory = NewType(\"CumDiscFutureRewardTrajectory\", RewardTrajectory)\n",
    "\n",
    "def cumulative_discounted_future_rewards(\n",
    "    *, trajectory: RewardTrajectory, gamma: float\n",
    ") -> CumDiscFutureRewardTrajectory:\n",
    "    \"\"\"2.2.1 Returns the cumulative discounted future rewards of a trajectory at each step of the trajectory.\n",
    "    \n",
    "    In the hugging face tutorial,\n",
    "    each element in the output is represented by $G_t$ where $t$ is the index of the element.\"\"\"\n",
    "    if len(trajectory) == 0:\n",
    "        raise ValueError(\"Trajectory needs at least one item.\")\n",
    "    if len(trajectory) == 1:\n",
    "        return RewardTrajectory([trajectory[0]])\n",
    "    discounted_rewards: List[Reward] = []\n",
    "    cumulative_reward: Reward = Reward(0)\n",
    "    for reward in reversed(trajectory):\n",
    "        cumulative_reward = Reward(reward + gamma * cumulative_reward)\n",
    "        discounted_rewards.append(cumulative_reward)\n",
    "    return RewardTrajectory(discounted_rewards[::-1])\n",
    "\n",
    "\n",
    "def test_cumulative_discounted_future_rewards() -> None:\n",
    "    # It's important to test our code, so we know it works as expected\n",
    "    # We tried to use ipytest but it wasn't working https://github.com/chmp/ipytest\n",
    "    assert cumulative_discounted_future_rewards(\n",
    "        trajectory=RewardTrajectory([-1]), gamma=0.5\n",
    "    ) == RewardTrajectory([-1])\n",
    "    assert cumulative_discounted_future_rewards(\n",
    "        trajectory=RewardTrajectory([0]), gamma=0.5\n",
    "    ) == RewardTrajectory([0])\n",
    "    assert cumulative_discounted_future_rewards(\n",
    "        trajectory=RewardTrajectory([0, 1]), gamma=0.5\n",
    "    ) == RewardTrajectory([0.5, 1])\n",
    "    assert cumulative_discounted_future_rewards(\n",
    "        trajectory=RewardTrajectory([0, 1, 1]), gamma=0.5\n",
    "    ) == RewardTrajectory([0.75, 1.5, 1])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # I can't get pytest to work with jupyter, so I'm just going to run the tests here\n",
    "    test_cumulative_discounted_future_rewards()\n",
    "    print(\"test_cumulative_discounted_future_rewards passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is the objective function. We want to sum the log probabilities of each action taken in the trajectory, multiplied by the discounted future rewards resulting from that action. We negate the log probabilities because we want to maximize the objective function, and the optimizer we are using is a minimizer. This is the REINFORCE score function.\n",
    "\n",
    "$J(\\theta) = \\frac{1}{T} \\sum_{t=0}^{T-1} G_t \\log \\pi_{\\theta}(a_t | s_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(*, policy: Policy, trajectory: Trajectory, gamma: float) -> Loss:\n",
    "    \"\"\"\n",
    "    2.2.2 Returns the likelihood of a trajectory given a policy.\n",
    "    Instead of doing 1/T, we normalize the cumulative discounted rewards as it says\n",
    "    to do in the tutorial.\n",
    "    Also we use torch.cat and sum for backprop reasons, so that backward can be called on the output.\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    cum_disc_rewards = normalize(\n",
    "        cumulative_discounted_future_rewards(\n",
    "            trajectory=RewardTrajectory([sar.reward for sar in trajectory]), gamma=gamma\n",
    "        )\n",
    "    )\n",
    "    for cum_disc_reward, sar in zip(cum_disc_rewards, trajectory):\n",
    "        loss.append(cum_disc_reward * -sar.log_prob)  # This is negative to turn maximization into minimization\n",
    "    return Loss(torch.cat(loss).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together, this is the training loop for the REINFORCE algorithm:\n",
    "\n",
    "1. Start with policy model $\\pi_{\\theta}$\n",
    "2. repeat:\n",
    "    1. Generate an episode $S_0, A_0, r_0, ..., S_{T-1}, A_{T-1}, r_{T-1}$ following $\\pi_{\\theta}$\n",
    "    2. for t from T-1 to 0:\n",
    "        1. $G_t = \\sum_{k=t}^{T-1} \\gamma^{k-t} r_k$\n",
    "    3. $L(\\theta) = \\frac{1}{T} \\sum_{t=0}^{T-1} G_t \\log \\pi_{\\theta}(a_t | s_t)$\n",
    "    4. Optimize $\\pi_{\\theta}$ using $\\nabla_{\\theta} L(\\theta)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "import torch.optim as optim\n",
    "\n",
    "def reinforce_train(*, env: Env, policy: Policy, optimizer: optim.Optimizer, gamma: float, num_episodes: int, max_t: int):\n",
    "    \"\"\"Algorithm 1 REINFORCE\"\"\"\n",
    "    assert gamma <= 1, \"Gamma should be less than or equal to 1\"\n",
    "    assert gamma > 0, \"Gamma should be greater than 0\"\n",
    "    assert num_episodes > 0, \"Number of episodes should be greater than 0\"\n",
    "    scores = []\n",
    "    for _ in trange(num_episodes):\n",
    "        # TODO: We could batch these episodes to get more stability\n",
    "        trajectory = collect_episode(env=env, policy=policy, max_t=max_t)\n",
    "        scores.append(sum([sar.reward for sar in trajectory]))\n",
    "        policy_loss = objective(policy=policy, trajectory=trajectory, gamma=gamma)\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()  # This gives us the gradient\n",
    "        optimizer.step()\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing NN's and Training Functions\n",
    "\n",
    "\n",
    "First we want to unit test this on the simplest environment we can possibly think of, something that if it does not work it **guarenteed** to be a coding error. Something like \"reward 1 if you repeat your input, 0 otherwise, end after 10 right answers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mock_env_all_right passed\n",
      "test_mock_env_all_wrong passed\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "\n",
    "from numpy import float32\n",
    "\n",
    "class MockEnv(gym.Env):\n",
    "    \"\"\"A dead simple environment for reinforcement learning that rewards the agent for going left.\n",
    "    Useful for unit testing.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, max_steps=10):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Discrete(1)\n",
    "        self.max_steps = max_steps\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action: Action) -> tuple[npt.NDArray[float32], Reward, bool, bool, dict]:\n",
    "        assert self.action_space.contains(action), f\"Invalid Action: {action}\"\n",
    "        \n",
    "        # If the state is 0, then the 0th action is the correct action\n",
    "        # If the state is 1, then the 1st action is the correct action\n",
    "        reward = 1 if action == self.state else -1\n",
    "        self.steps += 1\n",
    "        done = self.steps >= self.max_steps\n",
    "        if done:\n",
    "            return self.state, reward, done, False, {}\n",
    "        else:\n",
    "            self.state = np.array([random.choice([0.0, 1.0])])\n",
    "            return self.state, reward, done, False, {}\n",
    "        \n",
    "    def reset(self) -> tuple[npt.NDArray[float32], dict]:\n",
    "        self.state = np.array([random.choice([0.0, 1.0])])\n",
    "        self.steps = 0\n",
    "        return self.state, {}  # Return the first observation\n",
    "\n",
    "def test_mock_env_all_right() -> None:\n",
    "    \"\"\"Manually check the behavior of the mock environment. Perform all actions correctly.\"\"\"\n",
    "    max_steps = 10\n",
    "    env = MockEnv(max_steps=max_steps)\n",
    "    state, _ = env.reset()\n",
    "    for _ in range(max_steps-1):\n",
    "        next_state, reward, done, _, _ = env.step(int(state[0]))\n",
    "        assert reward == 1\n",
    "        assert done == False\n",
    "        state = next_state\n",
    "    next_state, reward, done, _, _ = env.step(int(state[0]))\n",
    "    assert reward == 1\n",
    "    assert done == True\n",
    "\n",
    "def test_mock_env_all_wrong() -> None:\n",
    "    \"\"\"Manually check the behavior of the mock environment. Perform all actions incorrectly.\"\"\"\n",
    "    max_steps = 10\n",
    "    env = MockEnv(max_steps=max_steps)\n",
    "    state, _ = env.reset()\n",
    "    for _ in range(max_steps-1):\n",
    "        next_state, reward, done, _, _ = env.step(1-int(state[0]))\n",
    "        assert reward == -1\n",
    "        assert done == False\n",
    "        state = next_state\n",
    "    next_state, reward, done, _, _ = env.step(1-int(state[0]))\n",
    "    assert reward == -1\n",
    "    assert done == True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_mock_env_all_right()\n",
    "    print(\"test_mock_env_all_right passed\")\n",
    "    test_mock_env_all_wrong()\n",
    "    print(\"test_mock_env_all_wrong passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e43b5d1bb44ae3b5c27de35dfef0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_reinforce_train passed\n"
     ]
    }
   ],
   "source": [
    "def test_reinforce_train() -> None:\n",
    "    \"\"\"Test the reinforce training loop on the mock environment.\"\"\"\n",
    "    env = MockEnv(max_steps=10)\n",
    "    policy = Policy(state_size=1, action_size=2, hidden_sizes=[16])\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "    scores = reinforce_train(env=env, policy=policy, optimizer=optimizer, gamma=1.0, num_episodes=100, max_t=10)\n",
    "    assert all([score == 10 for score in scores[90:]]), \"The last 10 scores should be 10\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_reinforce_train()\n",
    "    print(\"test_reinforce_train passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Environment\n",
    "\n",
    "Now that this has passed, we can be confident nothing obvious is wrong with the code, and we can move on to the cartpole environment.\n",
    "\n",
    "We choose a gamma that is non-1 to discount future rewards, but especially in the cartpole environment, setting it very close to 1 is beneficial, because the longer the pole is balanced, the more reward we get.\n",
    "\n",
    "We choose a small neural network and a fast learning rate, because this is not a hard problem.\n",
    "\n",
    "However, we do need to train longer than the hugging face tutorial, and I'm unsure why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5b89c7dc804fe0a0bfba7b20cc361c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "from continuing_education.lib.experiments import ExperimentManager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    LR = 1e-2\n",
    "    GAMMA = 1.0 # Cartpole benefits from a high gamma because the longer the pole is up, the higher the reward\n",
    "    HIDDEN_SIZES = [16, 16]\n",
    "    NUM_EPISODES= 1000\n",
    "    MAX_T = 100\n",
    "    for \n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = Policy(\n",
    "        state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "        action_size=ACTION_SPACE_SIZE,\n",
    "        hidden_sizes=HIDDEN_SIZES,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "    scores = reinforce_train(env=env, policy=policy, optimizer=optimizer, gamma=GAMMA, num_episodes=NUM_EPISODES, max_t=MAX_T)\n",
    "    # Calculate the mean of the last 10 % of the scores\n",
    "    last_10_percent_mean = sum(scores[int(NUM_EPISODES*0.9):]) / (NUM_EPISODES*0.1)\n",
    "    fig = px.line(scores, title=\"Scores over time\")\n",
    "    fig.show()\n",
    "    ExperimentManager(name=\"REINFORCE\", description=\"Main Results\", primary_metric=\"last_10_percent_mean\", file=__this_file).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements\n",
    "\n",
    "1. We should sample from actions instead of taking the argmax\n",
    "2. We should take a batch of episodes and optimize on the batch\n",
    "\n",
    "These should minimize the instability of the training process seen in the above graph, where it sometimes looses the gains it has made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplePolicy(Policy):\n",
    "    \"\"\"A classic policy network is one which takes in a state\n",
    "    and returns a probability distribution over the action space.\n",
    "    Act samples from the distribution instead of taking the greedy argmax.\"\"\"\n",
    "\n",
    "    def act(self, state: State) -> Tuple[Action, LogProb]:\n",
    "        \"\"\"Same as forward, instead of returning the entire distribution, we\n",
    "        sample from the distribution\n",
    "        along with the log probability of that action.\n",
    "        In testing mode, you can set argmax=True to take the greedy action.\n",
    "        \"\"\"\n",
    "        # First we got to convert out of numpy and into pytorch\n",
    "        state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Now we can run the forward pass, whos output is a probability distribution\n",
    "        # along the action space\n",
    "        pdf = self.forward(state_tensor)\n",
    "        assert torch.isclose(pdf.sum().cpu(), torch.Tensor([1.0])).all(), \"The output of the network should be a probability distribution\"\n",
    "        assert pdf.cpu().shape[-1] == self.action_size, \"The output of the network should be a probability distribution over the action space\"\n",
    "\n",
    "        # Now we want to get the action that corresponds to the highest probability\n",
    "        # TODO: We could sample from the pdf instead of taking the greedy argmax\n",
    "        m = torch.distributions.Categorical(pdf)\n",
    "        action_idx = m.sample()\n",
    "\n",
    "        # We also need the log probability of the action\n",
    "        # However, we are going to do backprop through the log probability of the action\n",
    "        # Therefore this needs to stay as a tensor\n",
    "        # The Category distribution in torch has a method for a backprop friendly log probability of one action from a multinomial distribution\n",
    "        log_prob = m.log_prob(action_idx)\n",
    "\n",
    "        # We return the action and the log probability of the action\n",
    "        return Action(action_idx.item()), log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e042aa7c7bde461fa9368de3dec12628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_reinforce_train_batch passed\n"
     ]
    }
   ],
   "source": [
    "def reinforce_train_batch(*, env: Env, policy: Policy, optimizer: optim.Optimizer, gamma: float, num_episodes: int, batch_size: int, max_t: int) -> None:\n",
    "    \"\"\"Algorithm 1 REINFORCE modified to use batched episodes.\n",
    "    equivalent to reinforce_train if batch_size=1\n",
    "    \"\"\"\n",
    "    assert gamma <= 1, \"Gamma should be less than or equal to 1\"\n",
    "    assert gamma > 0, \"Gamma should be greater than 0\"\n",
    "    assert num_episodes > 0, \"Number of episodes should be greater than 0\"\n",
    "    scores = []\n",
    "    for _ in trange(num_episodes):\n",
    "        policy_losses = []\n",
    "        _scores = []\n",
    "        for _ in range(batch_size):\n",
    "            trajectory = collect_episode(env=env, policy=policy, max_t=max_t)\n",
    "            _scores.append(sum([sar.reward for sar in trajectory]))\n",
    "            policy_losses.append(objective(policy=policy, trajectory=trajectory, gamma=gamma))\n",
    "        policy_loss = torch.stack(policy_losses).mean()\n",
    "        scores.append(sum(_scores) / batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()  # This gives us the gradient\n",
    "        optimizer.step()\n",
    "    return scores\n",
    "\n",
    "def test_reinforce_train_batch() -> None:\n",
    "    \"\"\"Test the reinforce training loop on the mock environment.\"\"\"\n",
    "    env = MockEnv(max_steps=10)\n",
    "    policy = SamplePolicy(state_size=1, action_size=2, hidden_sizes=[16])\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "    scores = reinforce_train_batch(env=env, policy=policy, optimizer=optimizer, gamma=1.0, num_episodes=100, batch_size=10, max_t=10)\n",
    "    assert all([score >= 9 for score in scores[90:]]), f\"The last 10 scores should be 10, maybe some 9s. Got: {scores}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_reinforce_train_batch()\n",
    "    print(\"test_reinforce_train_batch passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e7b1dd443c4e6ba3f6ba32b4dc5141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 10\n",
    "    NUM_EPISODES = 200\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = SamplePolicy(\n",
    "        state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "        action_size=ACTION_SPACE_SIZE,\n",
    "        hidden_sizes=HIDDEN_SIZES,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "    scores = reinforce_train_batch(env=env, policy=policy, optimizer=optimizer, gamma=GAMMA, num_episodes=NUM_EPISODES, batch_size=BATCH_SIZE, max_t=MAX_T)\n",
    "    # Calculate the mean of the last 10 % of the scores\n",
    "    last_10_percent_mean = sum(scores[int(NUM_EPISODES*0.9):]) / (NUM_EPISODES*0.1)\n",
    "    fig = px.line(scores, title=\"Scores over time\")\n",
    "    fig.show()\n",
    "    ExperimentManager(name=\"REINFORCE\", description=f\"Batch Size {BATCH_SIZE} + Sample Results\", primary_metric=\"last_10_percent_mean\", file=__this_file).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of three runs:\n",
    "\n",
    "1. Did very well and achieved the maximum score `git_commit:a3ccdfdd4b2dcd079f09cb9fffa1adfff47696d8`\n",
    "2. \n",
    "\n",
    "### Argmax, with batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0357d7a7fe54444adce2333ab9748da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "xaxis": "x",
         "y": [
          10.3,
          9.1,
          11,
          10.2,
          9.2,
          9.7,
          9,
          9.2,
          9.1,
          9.4,
          9.8,
          9.3,
          9.8,
          9.4,
          10,
          9.1,
          9.3,
          9.5,
          9.6,
          9.3,
          9.9,
          9.4,
          9.7,
          9.5,
          9.5,
          9.4,
          9.3,
          9.6,
          9.4,
          9.1,
          9,
          9.5,
          9.7,
          10.4,
          9.2,
          9.2,
          9.2,
          9.9,
          8.9,
          9.3,
          10.2,
          9.1,
          9.8,
          9.8,
          9,
          9.4,
          9,
          9,
          9.1,
          9.5,
          9.8,
          9.3,
          9.4,
          9.7,
          9.1,
          9.5,
          9.1,
          9.4,
          9.5,
          9.8,
          9.8,
          9.1,
          9.6,
          9.1,
          10.1,
          9.8,
          9.7,
          9.5,
          9.4,
          9.4,
          9.4,
          10,
          10.6,
          10.7,
          10.4,
          9.2,
          9.3,
          9.6,
          10.3,
          11.8,
          11.5,
          9.5,
          9.4,
          9.5,
          10.2,
          11.4,
          11.2,
          11.1,
          9.7,
          9.4,
          9.3,
          10.1,
          9.6,
          10,
          10.6,
          9.9,
          9.9,
          9,
          9.6,
          9.5,
          9.9,
          10.5,
          10,
          10.2,
          10.1,
          9.1,
          9.5,
          10,
          11.4,
          10.9,
          11.4,
          11.1,
          9.5,
          9.2,
          10.7,
          11.9,
          12.2,
          10.8,
          9.8,
          9.6,
          9.6,
          11,
          11,
          10.5,
          9.8,
          9.1,
          9.4,
          9.8,
          9.9,
          10.5,
          9.1,
          9.8,
          9.3,
          10.6,
          11.3,
          10.1,
          9.1,
          9.8,
          10.7,
          10.7,
          9.5,
          9.8,
          9.7,
          10.9,
          11.4,
          11.9,
          9.3,
          11.5,
          11.8,
          11.8,
          9.3,
          10.1,
          12.1,
          12.9,
          12.8,
          10.6,
          9.2,
          9.4,
          11.1,
          11.6,
          11,
          10.7,
          10.5,
          9.8,
          9.5,
          9.3,
          10.3,
          9.7,
          10.1,
          10.4,
          9.8,
          9.6,
          9.2,
          10.5,
          10.7,
          10.7,
          9.9,
          9.7,
          9.6,
          11.4,
          12.3,
          11.8,
          11.2,
          9.3,
          9.4,
          10.4,
          12.1,
          11,
          12,
          10.9,
          9.3,
          9.1,
          10.3,
          11.1,
          12.2,
          11.2,
          10.6,
          10.1,
          9.4,
          9.4
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scores over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:  jupytext --sync /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb\n",
      "[jupytext] Reading /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/lib/experiments/manager.py:43: UserWarning:\n",
      "\n",
      "There are unstaged changes in the repository. Please commit or stage them before running the experiment manager.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 10\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = Policy(\n",
    "        state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "        action_size=ACTION_SPACE_SIZE,\n",
    "        hidden_sizes=HIDDEN_SIZES,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "    scores = reinforce_train_batch(env=env, policy=policy, optimizer=optimizer, gamma=GAMMA, num_episodes=NUM_EPISODES, batch_size=BATCH_SIZE, max_t=MAX_T)\n",
    "    # Calculate the mean of the last 10 % of the scores\n",
    "    last_10_percent_mean = sum(scores[int(NUM_EPISODES*0.9):]) / (NUM_EPISODES*0.1)\n",
    "    fig = px.line(scores, title=\"Scores over time\")\n",
    "    fig.show()\n",
    "    ExperimentManager(name=\"REINFORCE\", description=f\"Batch Size {BATCH_SIZE} + Argmax Results\", primary_metric=\"last_10_percent_mean\", file=__this_file).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling, no batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb3cf093f1d432b99451c1a8dcd46d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "xaxis": "x",
         "y": [
          14,
          10,
          19,
          16,
          22,
          15,
          13,
          51,
          12,
          12,
          16,
          14,
          13,
          12,
          18,
          16,
          10,
          13,
          18,
          31,
          14,
          34,
          47,
          21,
          17,
          57,
          31,
          45,
          13,
          17,
          57,
          33,
          49,
          22,
          29,
          59,
          35,
          29,
          38,
          26,
          32,
          25,
          12,
          62,
          32,
          18,
          51,
          14,
          44,
          34,
          22,
          20,
          32,
          30,
          21,
          45,
          100,
          75,
          67,
          60,
          33,
          48,
          51,
          59,
          71,
          22,
          20,
          100,
          88,
          41,
          25,
          100,
          39,
          84,
          33,
          91,
          100,
          100,
          100,
          78,
          100,
          100,
          100,
          62,
          65,
          71,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          67,
          100,
          75,
          70,
          100,
          67,
          100,
          22,
          62,
          18,
          59,
          63,
          68,
          17,
          66,
          100,
          100,
          61,
          58,
          100,
          100,
          58,
          100,
          56,
          100,
          100,
          100,
          23,
          100,
          100,
          100,
          24,
          43,
          28,
          100,
          78,
          96,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          16,
          100,
          100,
          100,
          100,
          13,
          100,
          100,
          100,
          16,
          100,
          13,
          100,
          25,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scores over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:  jupytext --sync /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb\n",
      "[jupytext] Reading /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/lib/experiments/manager.py:43: UserWarning:\n",
      "\n",
      "There are unstaged changes in the repository. Please commit or stage them before running the experiment manager.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 1\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = SamplePolicy(\n",
    "        state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "        action_size=ACTION_SPACE_SIZE,\n",
    "        hidden_sizes=HIDDEN_SIZES,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "    scores = reinforce_train(env=env, policy=policy, optimizer=optimizer, gamma=GAMMA, num_episodes=NUM_EPISODES, max_t=MAX_T)\n",
    "    # Calculate the mean of the last 10 % of the scores\n",
    "    last_10_percent_mean = sum(scores[int(NUM_EPISODES*0.9):]) / (NUM_EPISODES*0.1)\n",
    "    fig = px.line(scores, title=\"Scores over time\")\n",
    "    fig.show()\n",
    "    ExperimentManager(name=\"REINFORCE\", description=f\"Batch Size {BATCH_SIZE} + Sample Results\", primary_metric=\"last_10_percent_mean\", file=__this_file).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both, but with smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2db5ac08814602a7c052eabc479a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "xaxis": "x",
         "y": [
          11,
          37,
          14.5,
          17,
          23.5,
          19.5,
          41.5,
          30,
          28.5,
          17.5,
          20,
          18,
          14.5,
          34.5,
          28.5,
          43.5,
          12.5,
          54.5,
          62,
          27.5,
          34.5,
          43.5,
          29.5,
          39.5,
          35.5,
          47,
          51,
          28.5,
          47.5,
          57.5,
          50,
          36,
          24.5,
          46,
          18.5,
          54.5,
          80.5,
          58.5,
          37.5,
          55.5,
          46,
          26.5,
          50,
          43,
          83.5,
          79,
          74.5,
          46.5,
          84.5,
          88,
          62,
          67.5,
          79,
          70,
          76.5,
          100,
          76,
          100,
          100,
          70.5,
          100,
          100,
          100,
          100,
          100,
          100,
          78.5,
          100,
          100,
          86,
          88.5,
          91.5,
          100,
          84,
          100,
          92.5,
          65.5,
          98.5,
          90,
          98.5,
          100,
          73,
          89,
          91.5,
          92.5,
          30.5,
          75,
          90.5,
          92,
          89.5,
          90.5,
          100,
          100,
          67.5,
          100,
          100,
          100,
          100,
          17.5,
          60.5,
          27,
          34,
          22,
          22.5,
          18.5,
          59,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          97,
          100,
          88.5,
          100,
          58,
          100,
          100,
          100,
          100,
          100,
          58.5,
          60,
          100,
          56.5,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scores over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:  jupytext --sync /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb\n",
      "[jupytext] Reading /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of /home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/policy_gradient_methods/reinforce/reinforce.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/Documents/Workspace/continuing_education/continuing_education/lib/experiments/manager.py:43: UserWarning:\n",
      "\n",
      "There are unstaged changes in the repository. Please commit or stage them before running the experiment manager.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 2\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    policy = SamplePolicy(\n",
    "        state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "        action_size=ACTION_SPACE_SIZE,\n",
    "        hidden_sizes=HIDDEN_SIZES,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "    scores = reinforce_train_batch(env=env, policy=policy, optimizer=optimizer, gamma=GAMMA, num_episodes=NUM_EPISODES, batch_size=BATCH_SIZE, max_t=MAX_T)\n",
    "    # Calculate the mean of the last 10 % of the scores\n",
    "    last_10_percent_mean = sum(scores[int(NUM_EPISODES*0.9):]) / (NUM_EPISODES*0.1)\n",
    "    fig = px.line(scores, title=\"Scores over time\")\n",
    "    fig.show()\n",
    "    ExperimentManager(name=\"REINFORCE\", description=f\"Batch Size {BATCH_SIZE} + Sample Results\", primary_metric=\"last_10_percent_mean\", file=__this_file).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Williams, R.J. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Mach Learn 8, 229256 (1992). https://doi.org/10.1007/BF00992696\n",
    "\n",
    "2. UNIT 4. POLICY GRADIENT WITH PYTORCH. Hugging Face. (n.d.). https://huggingface.co/learn/deep-rl-course/unit4"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "continuing-education-vJKa4-To-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
