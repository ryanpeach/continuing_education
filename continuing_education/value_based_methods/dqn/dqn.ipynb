{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    __this_file = Path().resolve() / \"dqn.ipynb\"  # jupyter does not have __file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from continuing_education.policy_gradient_methods.reinforce import collect_episode, SamplePolicy, Action, State, Env, cumulative_discounted_future_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning\n",
    "\n",
    "Lets quickly create a simple Q Learning Agent and test it on cartpole environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "class QLearningModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, *, state_size: int, action_size: int, hidden_sizes: list[int]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Notice that this is exactly the same as the Policy network from REINFORCE, because\n",
    "        we are still starting from the state and outputting an action. The difference is that\n",
    "        we will not softmax the output, because its not a probability distribution, but rather\n",
    "        a regressor that outputs the Q value of each action.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert len(hidden_sizes) > 0, \"Need at least one hidden layer\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # Dimensions in the network are (batch_size, input_size, output_size)\n",
    "        network: list[nn.Module] = []\n",
    "        network.append(\n",
    "            nn.Linear(state_size, hidden_sizes[0])\n",
    "        )  # Shape: (:, state_size, hidden_sizes[0])\n",
    "        network.append(nn.ReLU())\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            network.append(\n",
    "                nn.Linear(hidden_sizes[i], hidden_sizes[i + 1])\n",
    "            )  # Shape: (:, hidden_sizes[i], hidden_sizes[i+1])\n",
    "            network.append(nn.ReLU())\n",
    "        network.append(\n",
    "            nn.Linear(hidden_sizes[-1], action_size)\n",
    "        )  # Shape: (:, hidden_sizes[-1], action_size)\n",
    "        self.network = nn.Sequential(*network).to(DEVICE)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Takes a state tensor and returns logits along the action space\"\"\"\n",
    "        state = state.to(DEVICE)\n",
    "        return self.network(state)\n",
    "\n",
    "    def act(self, state: State) -> Action:\n",
    "        \"\"\"\n",
    "        Same as the policy network, but instead of softmaxing and sampling, \n",
    "        the network actually is a regressor returning real numbered values, and we are argmaxing over them.\n",
    "        We don't get a log_prob, and we don't pass a temperature, because Q networks cant handle stochastic policies.\n",
    "        \"\"\"\n",
    "        # First we got to convert out of numpy and into pytorch\n",
    "        state_tensor = torch.from_numpy(state).float().unsqueeze(0)\n",
    "\n",
    "        # Now we can run the forward pass, whos output is a probability distribution\n",
    "        # along the action space\n",
    "        action_values = self.forward(state_tensor)\n",
    "        assert (\n",
    "            action_values.cpu().shape[-1] == self.action_size\n",
    "        ), \"The output of the network should be a probability distribution over the action space\"\n",
    "\n",
    "        # Now we want to get the action that corresponds to the highest probability\n",
    "        # TODO: We could sample from the pdf instead of taking the greedy argmax\n",
    "        action_idx = torch.argmax(action_values)\n",
    "\n",
    "        # We return the action and the log probability of the action\n",
    "        return Action(int(action_idx.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import NewType\n",
    "\n",
    "@dataclass\n",
    "class SARS:\n",
    "    state: State\n",
    "    action: Action\n",
    "    reward: float\n",
    "    next_state: State\n",
    "    done: bool\n",
    "\n",
    "Trajectory = NewType(\"Trajectory\", list[SARS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "from gym import Env\n",
    "\n",
    "from continuing_education.policy_gradient_methods.reinforce.reinforce import Reward\n",
    "\n",
    "\n",
    "def collect_episode(\n",
    "    *, env: Env, value_network: QLearningModel, max_t: int = 1000\n",
    ") -> Generator[Trajectory, None, None]:\n",
    "    \"\"\"2.1 Returns the trajectory of one episode of using the value network.\n",
    "\n",
    "    The output is a list of SARS tuples, where each tuple represents a state, action, reward, next_state tuple.\n",
    "    \"\"\"\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    for _ in range(max_t):\n",
    "        action = value_network.act(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        yield SARS(\n",
    "            state=State(state),\n",
    "            action=action,\n",
    "            reward=Reward(reward),\n",
    "            next_state=State(next_state),\n",
    "            done=done,\n",
    "        )\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ActionReplayMemory:\n",
    "    \"\"\"The simplest kind of memory buffer for q learning.\n",
    "    This is a FIFO buffer of a fixed length that stores SAR objects from `continuing_education.policy_gradient_methods.reinforce.collect_episode`.\n",
    "    These SAR objects have been modified already using `continuing_education.policy_gradient_methods.reinforce.cumulative_discounted_future_rewards`\n",
    "    to replace their reward values.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size: int) -> None:\n",
    "        self.buffer: deque[SARS] = deque(maxlen=max_size)\n",
    "\n",
    "    def push(self, item: SARS) -> None:\n",
    "        self.buffer.append(item)\n",
    "\n",
    "    def sample(self, batch_size: int) -> list[SARS]:\n",
    "        if len(self.buffer) < batch_size:\n",
    "            raise ValueError(\"Not enough samples in the buffer\")\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from tqdm.notebook import trange\n",
    "import torch.optim as optim\n",
    "\n",
    "def objective(\n",
    "    *,\n",
    "    value_network: QLearningModel,\n",
    "    batch: list[SARS],\n",
    "    gamma: float,\n",
    ") -> Tensor:\n",
    "    \"\"\"The objective function for the DQN algorithm is simple regression loss.\"\"\"\n",
    "    states = torch.tensor([s.state for s in batch]).float().to(DEVICE) # shape (batch_size, state_size)\n",
    "    assert states.shape[1] == value_network.state_size, \"The state size of the value network should match the state size of the batch\"\n",
    "    actions = torch.tensor([s.action for s in batch]).long().to(DEVICE).unsqueeze(1) # shape (batch_size, 1)\n",
    "    assert actions.shape[1] == 1, \"The action should be a scalar value\"\n",
    "    rewards = torch.tensor([s.reward for s in batch]).float().to(DEVICE).unsqueeze(1) # shape (batch_size, 1)\n",
    "    assert rewards.shape[1] == 1, \"The reward should be a scalar value\"\n",
    "    next_states = torch.tensor([s.next_state for s in batch]).float().to(DEVICE) # shape (batch_size, state_size)\n",
    "    assert next_states.shape[1] == value_network.state_size, \"The state size of the value network should match the state size of the batch\"\n",
    "    dones = torch.tensor([s.done for s in batch]).float().to(DEVICE).unsqueeze(1) # shape (batch_size, 1)\n",
    "    assert dones.shape[1] == 1, \"The done should be a scalar value\"\n",
    "\n",
    "    # We are going to use the value network to predict the Q values for the current state\n",
    "    predicted_q_values = value_network.forward(states) # shape (batch_size, action_size)\n",
    "    assert predicted_q_values.shape[0] == len(batch), \"The first dimension of the output should match the batch size\"\n",
    "    assert predicted_q_values.shape[1] == value_network.action_size, \"The output of the network should be the same size as the action space\"\n",
    "    \n",
    "    # We are going to use the value network to predict the Q values for the next state\n",
    "    next_predicted_q_values = value_network.forward(next_states) # shape (batch_size, action_size)\n",
    "    assert next_predicted_q_values.shape[0] == len(batch), \"The first dimension of the output should match the batch size\"\n",
    "    assert next_predicted_q_values.shape[1] == value_network.action_size, \"The output of the network should be the same size as the action space\"\n",
    "\n",
    "    # Generate the Q Loss using the bellman equation\n",
    "    # Q(s, a) = r + gamma * max_a'(Q(s', a'))\n",
    "    next_action_value_predicted = next_predicted_q_values.max(1).values.unsqueeze(1)\n",
    "    bellman = rewards + gamma * next_action_value_predicted * (1.0 - dones)\n",
    "    assert bellman.shape[0] == len(batch), \"The first dimension of the output should match the batch size\"\n",
    "    assert bellman.shape[1] == 1, \"The bellman equation should output a scalar value\"\n",
    "\n",
    "    # We predict the Q values for the current state given the actual action, vs the predicted future rewards from the bellman equation\n",
    "    loss = nn.MSELoss()(predicted_q_values.gather(1, actions).unsqueeze(1), bellman)\n",
    "    assert loss.shape == (), \"The loss should be a scalar value\"\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn_train(\n",
    "    *,\n",
    "    env: Env,\n",
    "    value_network: QLearningModel,\n",
    "    memory: ActionReplayMemory,\n",
    "    optimizer: optim.Optimizer,\n",
    "    gamma: float,\n",
    "    num_episodes: int,\n",
    "    max_t: int,\n",
    "    batch_size: int,\n",
    ") -> list[Reward]:\n",
    "    \"\"\"Algorithm 1 REINFORCE\"\"\"\n",
    "    assert gamma <= 1, \"Gamma should be less than or equal to 1\"\n",
    "    assert gamma > 0, \"Gamma should be greater than 0\"\n",
    "    assert num_episodes > 0, \"Number of episodes should be greater than 0\"\n",
    "    scores: list[Reward] = []\n",
    "    for _ in trange(num_episodes):\n",
    "        _scores = []\n",
    "        for sars in collect_episode(\n",
    "            env=env, value_network=value_network, max_t=max_t\n",
    "        ):\n",
    "            memory.push(sars)\n",
    "            _scores.append(sars.reward)\n",
    "            if len(memory) > batch_size:\n",
    "                batch = memory.sample(batch_size)\n",
    "                loss = objective(value_network=value_network, batch=batch, gamma=gamma)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        scores.append(sum(_scores))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: (4,)\n",
      "Action size: 2\n",
      "Example state: (array([ 0.01853191,  0.00968877, -0.04009233,  0.0157542 ], dtype=float32), {})\n",
      "Action return: (array([ 0.01872568,  0.20536207, -0.03977724, -0.2893039 ], dtype=float32), 1.0, False, False, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "from continuing_education.policy_gradient_methods.reinforce.reinforce import get_environment_space\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OBSERVATION_SPACE_SHAPE, ACTION_SPACE_SIZE = get_environment_space(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dde594600e47cd892b6ec5cc65157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/tmp/ipykernel_32649/3957677735.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  states = torch.tensor([s.state for s in batch]).float().to(DEVICE) # shape (batch_size, state_size)\n",
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          9,
          9,
          10,
          9,
          11,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          11,
          10,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          9,
          9,
          10,
          9,
          8,
          8,
          9,
          10,
          8,
          9,
          9,
          10,
          9,
          9,
          8,
          9,
          9,
          9,
          8,
          9,
          11,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          8,
          8,
          10,
          10,
          9,
          8,
          10,
          10,
          10,
          9,
          11,
          9,
          10,
          10,
          9,
          10,
          9,
          8,
          10,
          10,
          8,
          8,
          9,
          10,
          9,
          10,
          9,
          10,
          11,
          9,
          10,
          9,
          8,
          10,
          9,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          8,
          9,
          8,
          11,
          9,
          10,
          8,
          10,
          9,
          8,
          9,
          9,
          10,
          10,
          8,
          10,
          9,
          10,
          9,
          9,
          9,
          10,
          8,
          9,
          10,
          10,
          8,
          9,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          9,
          11,
          9,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          11,
          8,
          10,
          10,
          10,
          10,
          10,
          8,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          10,
          8,
          9,
          8,
          9,
          9,
          10,
          8,
          9,
          8,
          10,
          9,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          8,
          8,
          10,
          11,
          9,
          10,
          9,
          9,
          10,
          10,
          10,
          9,
          10,
          9,
          9,
          10,
          11,
          9,
          10,
          8,
          10,
          9,
          10,
          10,
          10,
          11,
          10,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          10,
          9,
          8,
          9,
          10,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          11,
          11,
          8,
          10,
          9,
          10,
          10,
          11,
          9,
          10,
          9,
          10,
          10,
          8,
          10,
          10,
          10,
          10,
          8,
          10,
          9,
          10,
          8,
          10,
          10,
          8,
          9,
          9,
          10,
          9,
          8,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          9,
          9,
          11,
          9,
          10,
          10,
          10,
          10,
          11,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          9,
          8,
          10,
          10,
          9,
          10,
          9,
          10,
          11,
          10,
          10,
          8,
          10,
          9,
          10,
          9,
          10,
          11,
          8,
          9,
          10,
          10,
          9,
          9,
          9,
          10,
          9,
          9,
          10,
          8,
          9,
          10,
          9,
          10,
          9,
          8,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          9,
          9,
          10,
          11,
          9,
          10,
          9,
          10,
          10,
          9,
          8,
          9,
          10,
          10,
          9,
          10,
          10,
          8,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          10,
          10,
          8,
          8,
          10,
          10,
          8,
          9,
          10,
          9,
          8,
          9,
          9,
          10,
          9,
          10,
          9,
          8,
          10,
          10,
          10,
          9,
          10,
          9,
          8,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          10,
          11,
          10,
          8,
          10,
          8,
          9,
          9,
          10,
          9,
          8,
          10,
          10,
          8,
          10,
          9,
          9,
          9,
          10,
          10,
          9,
          10,
          10,
          8,
          9,
          10,
          9,
          10,
          9,
          11,
          9,
          9,
          8,
          10,
          8,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          10,
          9,
          10,
          10,
          8,
          9,
          10,
          11,
          9,
          9,
          8,
          10,
          11,
          8,
          8,
          8,
          9,
          9,
          9,
          10,
          9,
          9,
          9,
          8,
          9,
          9,
          10,
          11,
          9,
          10,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          8,
          9,
          9,
          10,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          11,
          10,
          9,
          10,
          10,
          8,
          9,
          10,
          10,
          10,
          9,
          10,
          10,
          8,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          8,
          10,
          10,
          10,
          9,
          10,
          9,
          9,
          10,
          8,
          8,
          10,
          9,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          9,
          8,
          10,
          9,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          10,
          9,
          9,
          9,
          8,
          9,
          8,
          8,
          9,
          9,
          10,
          8,
          10,
          11,
          10,
          10,
          10,
          8,
          9,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          10,
          8,
          9,
          10,
          10,
          10,
          10,
          8,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          9,
          8,
          11,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          11,
          10,
          9,
          9,
          10,
          9,
          9,
          9,
          10,
          8,
          9,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          8,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          8,
          10,
          9,
          9,
          9,
          9,
          10,
          9,
          8,
          10,
          9,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          8,
          10,
          8,
          9,
          9,
          10,
          9,
          8,
          10,
          8,
          9,
          9,
          10,
          10,
          9,
          9,
          9,
          9,
          9,
          10,
          11,
          9,
          10,
          11,
          9,
          9,
          9,
          9,
          10,
          9,
          11,
          9,
          10,
          9,
          9,
          10,
          8,
          9,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          10,
          9,
          9,
          10,
          8,
          8,
          10,
          10,
          10,
          8,
          9,
          8,
          9,
          9,
          9,
          9,
          10,
          8,
          9,
          10,
          10,
          9,
          10,
          9,
          9,
          9,
          9,
          10,
          9,
          10,
          8,
          10,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          10,
          10,
          8,
          10,
          9,
          8,
          8,
          9,
          10,
          10,
          10,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          10,
          10,
          9,
          8,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          9,
          9,
          8,
          10,
          9,
          10,
          9,
          10,
          11,
          10,
          10,
          9,
          10,
          9,
          9,
          8,
          10,
          9,
          10,
          9,
          9,
          10,
          9,
          8,
          10,
          10,
          10,
          8,
          8,
          9,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          8,
          9,
          8,
          9,
          9,
          8,
          9,
          8,
          10,
          10,
          10,
          10,
          10,
          10,
          8,
          9,
          9,
          8,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          9,
          10,
          9,
          11,
          10,
          9,
          9,
          8,
          9,
          9,
          9,
          9,
          10,
          9,
          10,
          11,
          10,
          8,
          9,
          10,
          10,
          9,
          9,
          9,
          10,
          10,
          9,
          9,
          9,
          8,
          10,
          10,
          8,
          10,
          10,
          10,
          9,
          9,
          10,
          8,
          9,
          9,
          8,
          10,
          9,
          9,
          8,
          10,
          9,
          9,
          9,
          9,
          9
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scores over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9aa4cb0037415a91714798997e90ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n",
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "xaxis": "x",
         "y": [
          11,
          10,
          9,
          9,
          8,
          10,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          11,
          10,
          9,
          10,
          11,
          8,
          9,
          9,
          9,
          8,
          10,
          10,
          9,
          8,
          10,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          8,
          8,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          10,
          9,
          10,
          9,
          9,
          10,
          10,
          11,
          9,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          8,
          9,
          8,
          10,
          9,
          9,
          10,
          10,
          10,
          9,
          9,
          8,
          9,
          9,
          10,
          9,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          8,
          10,
          10,
          8,
          11,
          8,
          8,
          8,
          10,
          9,
          10,
          10,
          10,
          9,
          10,
          10,
          9,
          9,
          8,
          9,
          8,
          10,
          11,
          8,
          10,
          10,
          9,
          9,
          10,
          10,
          10,
          9,
          10,
          10,
          10,
          8,
          10,
          10,
          9,
          9,
          10,
          10,
          10,
          8,
          10,
          9,
          9,
          9,
          10,
          8,
          10,
          9,
          9,
          10,
          8,
          10,
          9,
          9,
          10,
          11,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          9,
          9,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          11,
          9,
          10,
          10,
          10,
          9,
          8,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          8,
          9,
          9,
          9,
          9,
          10,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          10,
          9,
          8,
          10,
          10,
          10,
          9,
          8,
          9,
          11,
          8,
          9,
          10,
          9,
          9,
          8,
          9,
          8,
          9,
          10,
          9,
          10,
          9,
          9,
          8,
          10,
          9,
          10,
          9,
          10,
          9,
          9,
          8,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          10,
          8,
          10,
          9,
          10,
          9,
          10,
          8,
          9,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          10,
          10,
          11,
          9,
          10,
          8,
          9,
          10,
          9,
          9,
          10,
          10,
          9,
          10,
          10,
          9,
          8,
          10,
          8,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          8,
          9,
          9,
          9,
          9,
          10,
          10,
          11,
          10,
          10,
          10,
          10,
          9,
          9,
          10,
          8,
          8,
          9,
          9,
          10,
          10,
          10,
          9,
          10,
          10,
          9,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          9,
          11,
          10,
          8,
          9,
          10,
          9,
          9,
          8,
          10,
          10,
          9,
          10,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          8,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          9,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          10,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          8,
          10,
          8,
          10,
          10,
          9,
          9,
          11,
          10,
          10,
          9,
          11,
          8,
          9,
          10,
          10,
          10,
          10,
          8,
          10,
          11,
          10,
          10,
          10,
          9,
          8,
          10,
          8,
          10,
          10,
          9,
          8,
          8,
          9,
          10,
          10,
          9,
          8,
          9,
          10,
          10,
          10,
          8,
          8,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          9,
          10,
          8,
          10,
          9,
          10,
          8,
          10,
          8,
          9,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          8,
          9,
          10,
          9,
          8,
          9,
          9,
          9,
          8,
          10,
          10,
          10,
          9,
          10,
          8,
          10,
          8,
          9,
          10,
          11,
          10,
          9,
          10,
          8,
          9,
          9,
          9,
          9,
          11,
          10,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          8,
          8,
          10,
          11,
          8,
          10,
          9,
          10,
          10,
          10,
          9,
          10,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          8,
          10,
          10,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          9,
          11,
          10,
          9,
          10,
          10,
          8,
          9,
          10,
          8,
          10,
          8,
          9,
          9,
          9,
          10,
          10,
          10,
          8,
          9,
          9,
          10,
          8,
          9,
          9,
          8,
          10,
          9,
          8,
          10,
          10,
          8,
          9,
          9,
          10,
          10,
          10,
          9,
          9,
          9,
          8,
          10,
          9,
          11,
          9,
          9,
          9,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          8,
          9,
          8,
          8,
          9,
          9,
          9,
          8,
          10,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          9,
          9,
          10,
          8,
          10,
          9,
          9,
          8,
          9,
          9,
          9,
          10,
          10,
          10,
          9,
          8,
          9,
          8,
          9,
          10,
          10,
          10,
          8,
          9,
          9,
          8,
          10,
          9,
          10,
          9,
          10,
          8,
          9,
          10,
          8,
          9,
          8,
          9,
          9,
          10,
          10,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          11,
          10,
          9,
          9,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          10,
          8,
          9,
          8,
          9,
          9,
          9,
          9,
          10,
          8,
          10,
          10,
          9,
          8,
          8,
          10,
          9,
          9,
          10,
          10,
          9,
          8,
          9,
          10,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          8,
          10,
          9,
          9,
          10,
          10,
          10,
          9,
          9,
          9,
          9,
          11,
          9,
          9,
          9,
          10,
          10,
          8,
          9,
          9,
          8,
          10,
          9,
          9,
          9,
          11,
          8,
          8,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          8,
          9,
          10,
          9,
          9,
          9,
          10,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          9,
          9,
          9,
          10,
          10,
          9,
          10,
          9,
          10,
          11,
          8,
          9,
          8,
          10,
          9,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          8,
          10,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          9,
          9,
          9,
          10,
          9,
          8,
          8,
          9,
          9,
          9,
          8,
          9,
          9,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          9,
          10,
          9,
          9,
          10,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          10,
          9,
          9,
          10,
          10,
          8,
          9,
          9,
          9,
          9,
          8,
          9,
          10,
          10,
          9,
          10,
          10,
          10,
          9,
          9,
          10,
          8,
          9,
          8,
          9,
          10,
          9,
          9,
          9,
          11,
          10,
          10,
          10,
          10,
          8,
          9,
          11,
          10,
          10,
          9,
          9,
          10,
          9,
          10,
          9,
          9,
          9,
          10,
          10,
          10,
          8,
          10,
          10,
          8,
          9,
          10,
          9,
          11,
          8,
          10,
          8,
          11,
          9,
          9,
          10,
          10,
          10,
          9,
          10,
          8,
          11,
          8,
          9,
          10,
          10,
          9,
          9,
          10,
          10,
          10,
          9,
          9,
          9,
          9,
          9,
          8,
          10,
          8,
          10,
          9,
          9,
          10,
          10,
          9,
          10,
          10,
          11,
          10,
          10,
          10,
          8,
          11,
          10,
          10,
          10,
          9,
          9,
          9,
          9,
          9,
          9,
          8,
          9,
          10,
          10,
          9,
          10,
          9,
          10,
          9,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          9,
          9,
          9,
          10,
          8,
          9,
          9,
          9,
          8,
          10,
          9,
          8,
          9,
          10,
          10,
          9,
          11,
          10,
          8,
          9,
          10,
          9,
          8,
          9,
          10,
          9,
          9,
          10,
          9,
          9,
          10,
          9,
          10,
          10,
          10,
          8,
          8,
          9,
          10,
          9,
          9,
          8,
          9,
          9,
          9,
          10,
          8,
          10,
          9,
          9,
          10,
          10
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Scores over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8523f7ef8c1043edbbb7cab20d126d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning:\n",
      "\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\n",
      "/home/ryanpeach/.pyenv/versions/3.11.6/envs/continuing_education/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import plotly.express as px\n",
    "from continuing_education.lib.experiments import ExperimentManager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    LR = 1e-2\n",
    "    GAMMA = 1.0  # Cartpole benefits from a high gamma because the longer the pole is up, the higher the reward\n",
    "    HIDDEN_SIZES = [16, 16]\n",
    "    NUM_EPISODES = 1000\n",
    "    MAX_T = 100\n",
    "    BATCH_SIZE = 64\n",
    "    MAX_MEMORY = 10000\n",
    "    # Do this a few times to prove consistency\n",
    "    last_10_percent_mean = []\n",
    "    for _ in range(3):\n",
    "        env = gym.make(\"CartPole-v1\")\n",
    "        value_network = QLearningModel(\n",
    "            state_size=OBSERVATION_SPACE_SHAPE[0],\n",
    "            action_size=ACTION_SPACE_SIZE,\n",
    "            hidden_sizes=HIDDEN_SIZES,\n",
    "        ).to(DEVICE)\n",
    "        optimizer = optim.Adam(value_network.parameters(), lr=LR)\n",
    "        scores = dqn_train(\n",
    "            env=env,\n",
    "            value_network=value_network,\n",
    "            optimizer=optimizer,\n",
    "            gamma=GAMMA,\n",
    "            num_episodes=NUM_EPISODES,\n",
    "            max_t=MAX_T,\n",
    "            memory=ActionReplayMemory(MAX_MEMORY),\n",
    "            batch_size=64,\n",
    "        )\n",
    "        # Calculate the mean of the last 10 % of the scores\n",
    "        last_10_percent_mean.append(\n",
    "            sum(scores[int(NUM_EPISODES * 0.9) :]) / (NUM_EPISODES * 0.1)\n",
    "        )\n",
    "        fig = px.line(scores, title=\"Scores over time\")\n",
    "        fig.show()\n",
    "    ExperimentManager(\n",
    "        name=\"DQN\",\n",
    "        description=\"Main Results\",\n",
    "        primary_metric=\"last_10_percent_mean\",\n",
    "        file=__this_file,\n",
    "    ).commit(metrics={\"last_10_percent_mean\": last_10_percent_mean})"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "continuing_education",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
